{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T11:33:27.062414Z",
     "start_time": "2021-07-07T11:33:25.973597Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter \n",
    "from sklearn.preprocessing import scale\n",
    "from modAL.density import information_density\n",
    "np.random.seed(42)\n",
    "import math\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T11:39:10.762646Z",
     "start_time": "2021-07-07T11:39:07.063794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: Counter({0: 43930})\n",
      "43930\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "ft:挑选后的特征\n",
    "t:特征对应金标准(无)\n",
    "name:样本名称\n",
    "c: 特征对应簇\n",
    "'''\n",
    "df1 = pd.read_csv('./feats_bank_train_1111.csv',header = None)\n",
    "# print(df1.shape)\n",
    "fts = df1.values #特征样本/256维\n",
    "# ft = scale(ft)\n",
    "\n",
    "df2 = pd.read_csv(\n",
    "    './train_1111.txt',\n",
    "                  sep = ' ',header = None)\n",
    "names = df2.iloc[:,0].values #图片位置名称\n",
    "t = df2.iloc[:,1].values #金标准0/1\n",
    "print('Original dataset:', Counter(t))\n",
    "print(len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T11:39:29.466431Z",
     "start_time": "2021-07-07T11:39:29.463955Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_index1(lst=None, item=''):\n",
    "    tmp = []\n",
    "    tag = 0\n",
    "    for i in lst:\n",
    "        if i == item:\n",
    "            tmp.append(tag)\n",
    "        tag += 1\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T11:39:31.164889Z",
     "start_time": "2021-07-07T11:39:30.960151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'train': 43930})\n"
     ]
    }
   ],
   "source": [
    "bag = []\n",
    "for name in names:\n",
    "    (filepath, filename) = os.path.split(name)\n",
    "    (filepath, filename) = os.path.split(filepath)\n",
    "\n",
    "#     bag.append(filename.split('_')[0])\n",
    "    bag.append(filename)\n",
    "print(Counter(bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T11:46:42.781948Z",
     "start_time": "2021-07-07T11:46:42.777301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train']\n"
     ]
    }
   ],
   "source": [
    "bag_index=list(set(bag))\n",
    "print(bag_index)\n",
    "len(bag_index)\n",
    "sel_num = 12000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T11:46:50.888560Z",
     "start_time": "2021-07-07T11:46:47.606384Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag 1 finished!\n",
      "Resampled dataset: Counter({'train': 12000})\n",
      "12000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 12000})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Representation/Outlier\n",
    "'''\n",
    "import math\n",
    "\n",
    "index=[] #index[i]表示第i个聚类对应的index列表\n",
    "ft_part=[] #ft_part[i]表示第i个聚类对应的特征向量列表\n",
    "new_index=[] #新列表\n",
    "novel_preds = []\n",
    "\n",
    "for i in bag_index:\n",
    "    index.append(get_index1(bag, i))\n",
    "    ft_part.append(torch.Tensor(fts[get_index1(bag, i)]))\n",
    "#     ft_part.append(torch.Tensor([fts[index[i]]]))\n",
    "\n",
    "\n",
    "for i in range(len(bag_index)):\n",
    "#     centroids = farthest_point_sample(ft_part[i], sel_num).numpy().flatten()\n",
    "#     clf = IsolationForest(contamination=ratio,n_jobs=20).fit(ft_part[i])\n",
    "#     clf = LocalOutlierFactor(contamination=ratio,n_jobs=20).fit(ft_part[i])\n",
    "    density = information_density(ft_part[i], 'cosine')#cosine/euclidean\n",
    "#     score = clf.negative_outlier_factor_\n",
    "#     novel_pred = clf.fit_predict(ft_part[i])\n",
    "#     novel_preds.append(score)\n",
    "#     avg = np.mean(score)\n",
    "#     novel_pred = (score <= avg)\n",
    "#     centroids = np.where(novel_pred==True)\n",
    "#     new_index.extend(np.array(index[i])[centroids])\n",
    "#     print('bag '+str(i+1)+' finished!')\n",
    "\n",
    "#     centroids = np.where(novel_pred==-1)\n",
    "    centroids = np.argsort(density)[:sel_num]\n",
    "#     new_index.extend(index[i][li])\n",
    "#     print(\"Sampled pts: \", centroids)\n",
    "\n",
    "\n",
    "#     clf = OneClassSVM(gamma='auto').fit(ft_part[i])\n",
    "#     clf = EllipticEnvelope().fit(ft_part[i])\n",
    "#     score = clf.score_samples(ft_part[i])\n",
    "#     centroids=np.argsort(score)[:sel_num]\n",
    "    new_index.extend(np.array(index[i])[centroids])\n",
    "    print('bag '+str(i+1)+' finished!')\n",
    "    \n",
    "ft_sel = fts[new_index]\n",
    "# t_sel = t[new_index]\n",
    "# bag_sel = np.array(bag)[new_index]\n",
    "name_sel = names[new_index]\n",
    "\n",
    "from collections import Counter \n",
    "print('Resampled dataset:', Counter(bag_sel))\n",
    "print(len(name_sel))\n",
    "Counter(t_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T11:49:16.485514Z",
     "start_time": "2021-07-07T11:49:16.453974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "注意保存csv的后缀\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "注意保存csv的后缀\n",
    "'''\n",
    "print(__doc__)\n",
    "dataframe1 = pd.DataFrame({'image_name':name_sel})\n",
    "dataframe1.to_csv(\"./train_path_sample_o30_cos.txt\",\n",
    "                  index=False,sep=' ',header = None)\n",
    "\n",
    "# dataframe2 = pd.DataFrame(ft_sel)\n",
    "# dataframe2.to_csv(\"../FeatureBank/cifar10_1000_ex/1%/cifar10_1000_1%_FB/test_cifar10_1000_1%_fb.csv\",\n",
    "#                   index=False,sep=' ',header = None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
